{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cc632f-e07d-4f17-bdda-1dc822ef6043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to 'drone_route_with_aruco_locations.csv' and the processed video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calibrate_camera():\n",
    "    # Camera calibration function (to be filled with your calibration routine)\n",
    "    # This is a placeholder example using hypothetical values\n",
    "    camera_matrix = np.array([[1000, 0, 320], [0, 1000, 240], [0, 0, 1]], dtype=np.float32)\n",
    "    dist_coeffs = np.array([0.1, -0.05, 0.001, 0.0, 0.0], dtype=np.float32)\n",
    "    return camera_matrix, dist_coeffs\n",
    "\n",
    "\n",
    "# Load video and log file\n",
    "video_path = 'first/challengeB.mp4'\n",
    "log_path = 'first/log1.csv'\n",
    "\n",
    "#video_path = 'second/challengeB.mp4'\n",
    "#log_path = 'second/log1.csv'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "log_data = pd.read_csv(log_path)\n",
    "\n",
    "# Calibrate camera\n",
    "camera_matrix, dist_coeffs = calibrate_camera()\n",
    "\n",
    "# Aruco dictionary and detector parameters\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "parameters.adaptiveThreshConstant = 7\n",
    "parameters.minMarkerPerimeterRate = 0.03\n",
    "parameters.maxMarkerPerimeterRate = 4.0\n",
    "parameters.polygonalApproxAccuracyRate = 0.05\n",
    "\n",
    "# Output video settings\n",
    "output_video_path = 'OutPuts/first/processed_video.mp4'\n",
    "#output_video_path = 'OutPuts/second/processed_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Data storage for CSV\n",
    "csv_data = []\n",
    "\n",
    "# Process each frame in the video\n",
    "frame_idx = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    log_entry = log_data.iloc[frame_idx]\n",
    "\n",
    "    # Assuming the columns are named 'Yaw', 'Height', 'Pitch', 'Roll'\n",
    "    yaw, height, pitch, roll = log_entry['Yaw'], log_entry['height'], log_entry['pitch'], log_entry['roll']\n",
    "\n",
    "    # Pre-process the frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)  # Improve contrast\n",
    "\n",
    "    # Detect markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.19, camera_matrix, dist_coeffs)\n",
    "        for i in range(len(ids)):\n",
    "            aruco_id = ids[i][0]\n",
    "            tvec = tvecs[i].flatten()\n",
    "            distance = np.linalg.norm(tvec)\n",
    "\n",
    "            # Create the rotation matrix from the rotation vector\n",
    "            rmat, _ = cv2.Rodrigues(rvecs[i])\n",
    "            # Create the projection matrix\n",
    "            projection_matrix = np.hstack((rmat, tvec.reshape(-1, 1)))\n",
    "            _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(projection_matrix)\n",
    "            yaw, pitch, roll = euler_angles.flatten()\n",
    "\n",
    "            # QR 2D coordinates\n",
    "            qr_2d = corners[i][0].tolist()\n",
    "            left_up = tuple(map(int, qr_2d[0]))\n",
    "            right_up = tuple(map(int, qr_2d[1]))\n",
    "            right_down = tuple(map(int, qr_2d[2]))\n",
    "            left_down = tuple(map(int, qr_2d[3]))\n",
    "\n",
    "            # Draw rectangle and ID on the frame\n",
    "            cv2.polylines(frame, [np.int32(qr_2d)], True, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, str(aruco_id), left_up, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Store CSV data\n",
    "            csv_data.append({\n",
    "                'Frame ID': frame_idx,\n",
    "                'QR id': aruco_id,\n",
    "                'QR 2D': f\"{left_up},{right_up},{right_down},{left_down}\",\n",
    "                'QR 3D': f\"dist: {distance}, yaw: {yaw}, pitch: {pitch}, roll: {roll}\"\n",
    "            })\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Save results to CSV\n",
    "result_df = pd.DataFrame(csv_data)\n",
    "result_df.to_csv(\n",
    "    'OutPuts/first/drone_route_with_aruco_locations.csv',\n",
    "    index=False)\n",
    "#result_df.to_csv(\n",
    "#    'OutPuts/second/drone_route_with_aruco_locations.csv',\n",
    "#    index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'drone_route_with_aruco_locations.csv' and the processed video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45b614-0db9-437d-afc6-3b92c7cb932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
